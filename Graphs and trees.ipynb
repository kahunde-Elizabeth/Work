{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KAHUNDE ELIZABETH B30293 S24B38/003"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Graphs (10 Marks)\n",
    "\n",
    "#### Definition of Graphs\n",
    "\n",
    "A graph is a data structure that consists of a set of vertices (or nodes) and a set of edges that connect pairs of vertices. Graphs are used to represent relationships between objects.\n",
    "\n",
    "#### Graph Notation (G(V, E))\n",
    "\n",
    "- **G(V, E)**: A graph is denoted as G(V, E), where:\n",
    "  - **V** is the set of vertices.\n",
    "  - **E** is the set of edges, where each edge connects a pair of vertices.\n",
    "\n",
    "#### Applications of Graphs\n",
    "\n",
    "Graphs are used in various applications, including:\n",
    "- **Social Networks**: Representing relationships between users.\n",
    "- **Transportation Networks**: Modeling routes and connections between locations.\n",
    "- **Computer Networks**: Representing connections between computers or devices.\n",
    "- **Web Graphs**: Representing links between web pages.\n",
    "- **Biological Networks**: Modeling interactions between genes or proteins.\n",
    "\n",
    "#### Comparison: Graphs vs Trees\n",
    "\n",
    "- **Graphs**:\n",
    "  - Can have cycles.\n",
    "  - Can be directed or undirected.\n",
    "  - Can have multiple edges between the same pair of vertices.\n",
    "  - Used for more complex relationships and networks.\n",
    "\n",
    "- **Trees**:\n",
    "  - A special type of graph with no cycles.\n",
    "  - Always connected and acyclic.\n",
    "  - Used for hierarchical structures like file systems, organizational charts, etc.\n",
    "\n",
    "#### Types of Graphs\n",
    "\n",
    "1. **Directed vs Undirected**:\n",
    "   - **Directed Graph**: Edges have a direction, indicating a one-way relationship.\n",
    "   - **Undirected Graph**: Edges have no direction, indicating a two-way relationship.\n",
    "\n",
    "2. **Weighted vs Unweighted**:\n",
    "   - **Weighted Graph**: Edges have weights representing the cost or distance between vertices.\n",
    "   - **Unweighted Graph**: Edges have no weights.\n",
    "\n",
    "3. **Connected vs Disconnected**:\n",
    "   - **Connected Graph**: There is a path between every pair of vertices.\n",
    "   - **Disconnected Graph**: There are vertices that are not connected by any path.\n",
    "\n",
    "4. **Cyclic vs Acyclic**:\n",
    "   - **Cyclic Graph**: Contains at least one cycle.\n",
    "   - **Acyclic Graph**: Contains no cycles.\n",
    "\n",
    "5. **Special Graphs**:\n",
    "   - **Bipartite Graph**: Vertices can be divided into two disjoint sets such that every edge connects a vertex in one set to a vertex in the other set.\n",
    "   - **Planar Graph**: Can be drawn on a plane without any edges crossing.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "This code creates a directed, weighted graph with 5 nodes and visualizes it using NetworkX and Matplotlib.\n",
    "\n",
    "### Summary\n",
    "\n",
    "Graphs are versatile data structures used to represent relationships between objects. They come in various types, including directed, undirected, weighted, unweighted, connected, disconnected, cyclic, acyclic, and special graphs like bipartite and planar graphs. Understanding the differences between these types and when to use each structure is crucial for solving complex problems in computer science and related fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Graph Visualization using NetworkX\n",
    "\n",
    "#Here is an example of how to visualize a graph using the NetworkX library in Python:\n",
    "\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add nodes\n",
    "G.add_nodes_from([1, 2, 3, 4, 5])\n",
    "\n",
    "# Add edges with weights\n",
    "G.add_edge(1, 2, weight=1)\n",
    "G.add_edge(2, 3, weight=2)\n",
    "G.add_edge(3, 4, weight=3)\n",
    "G.add_edge(4, 5, weight=4)\n",
    "G.add_edge(5, 1, weight=5)\n",
    "\n",
    "# Draw the graph\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw(G, pos, with_labels=True, node_color='lightblue', node_size=500, font_size=10, font_weight='bold')\n",
    "labels = nx.get_edge_attributes(G, 'weight')\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=labels)\n",
    "\n",
    "# Show the plot\n",
    "plt.title(\"Directed Weighted Graph\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Terminology & Properties (5 Marks)\n",
    "\n",
    "#### Vertex, Edge, Degree (indegree, outdegree)\n",
    "\n",
    "- **Vertex (Node)**: A vertex is a fundamental unit of a graph, representing an entity or a point. In graph notation, vertices are typically denoted by V.\n",
    "\n",
    "- **Edge**: An edge is a connection between two vertices in a graph. It represents a relationship or link between the vertices. In graph notation, edges are typically denoted by E.\n",
    "\n",
    "- **Degree**:\n",
    "  - **Indegree**: The number of incoming edges to a vertex in a directed graph.\n",
    "  - **Outdegree**: The number of outgoing edges from a vertex in a directed graph.\n",
    "  - **Degree (Undirected Graph)**: The number of edges connected to a vertex.\n",
    "\n",
    "#### Adjacent Vertices (Neighbors)\n",
    "\n",
    "- **Adjacent Vertices (Neighbors)**: Two vertices are adjacent (or neighbors) if they are connected by an edge. In other words, there is a direct link between them.\n",
    "\n",
    "#### Path, Cycles, and Loops\n",
    "\n",
    "- **Path**: A path in a graph is a sequence of vertices connected by edges, where each vertex is visited only once. A path is defined by the order of vertices and edges traversed.\n",
    "\n",
    "- **Cycle**: A cycle is a path that starts and ends at the same vertex, with no other vertices repeated. In a cycle, the first and last vertices are the same.\n",
    "\n",
    "- **Loop**: A loop is an edge that connects a vertex to itself. It is a special case of a cycle with only one vertex.\n",
    "\n",
    "#### Connectivity (Strongly Connected, Weakly Connected, Disjoint Graphs)\n",
    "\n",
    "- **Connectivity**: Connectivity in a graph refers to the ability to reach one vertex from another vertex through a sequence of edges.\n",
    "\n",
    "  - **Strongly Connected**: A directed graph is strongly connected if there is a path from any vertex to every other vertex and vice versa. In other words, every vertex is reachable from every other vertex.\n",
    "\n",
    "  - **Weakly Connected**: A directed graph is weakly connected if replacing all of its directed edges with undirected edges produces a connected undirected graph. In other words, there is a path between any two vertices if the direction of edges is ignored.\n",
    "\n",
    "  - **Disjoint Graphs**: Disjoint graphs (or disconnected graphs) are graphs that consist of two or more components that have no vertices or edges in common. In other words, there is no path between vertices in different components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Representation & Storage (10 Marks)\n",
    "\n",
    "#### Adjacency Matrix\n",
    "\n",
    "**Definition**:\n",
    "An adjacency matrix is a 2D array (or matrix) used to represent a graph. The rows and columns of the matrix represent the vertices of the graph, and the entries in the matrix indicate whether there is an edge between the vertices.\n",
    "\n",
    "**Structure**:\n",
    "- For a graph with `n` vertices, the adjacency matrix is an `n x n` matrix.\n",
    "- If there is an edge from vertex `i` to vertex `j`, the entry `matrix[i][j]` is set to `1` (or the weight of the edge in the case of a weighted graph).\n",
    "- If there is no edge, the entry is set to `0`.\n",
    "\n",
    "**Example**:\n",
    "Consider a graph with 4 vertices (0, 1, 2, 3) and edges (0-1), (0-2), (1-2), and (2-3).\n",
    "\n",
    "Adjacency Matrix:\n",
    "```\n",
    "  0 1 2 3\n",
    "0 0 1 1 0\n",
    "1 0 0 1 0\n",
    "2 0 0 0 1\n",
    "3 0 0 0 0\n",
    "```\n",
    "\n",
    "**Advantages**:\n",
    "- Simple and easy to implement.\n",
    "- Efficient for dense graphs where the number of edges is close to the number of vertices squared (`O(n^2)`).\n",
    "\n",
    "**Disadvantages**:\n",
    "- Requires `O(n^2)` space, which can be inefficient for sparse graphs.\n",
    "- Checking for the existence of an edge takes `O(1)` time, but iterating over all edges takes `O(n^2)` time.\n",
    "\n",
    "#### Adjacency List\n",
    "\n",
    "**Definition**:\n",
    "An adjacency list is a collection of lists or arrays used to represent a graph. Each vertex has a list of adjacent vertices (i.e., vertices connected by an edge).\n",
    "\n",
    "**Structure**:\n",
    "- For a graph with `n` vertices, the adjacency list is an array of `n` lists.\n",
    "- Each list at index `i` contains the vertices adjacent to vertex `i`.\n",
    "\n",
    "**Example**:\n",
    "Consider the same graph with 4 vertices (0, 1, 2, 3) and edges (0-1), (0-2), (1-2), and (2-3).\n",
    "\n",
    "Adjacency List:\n",
    "```\n",
    "0: [1, 2]\n",
    "1: [2]\n",
    "2: [3]\n",
    "3: []\n",
    "```\n",
    "\n",
    "**Advantages**:\n",
    "- Requires `O(n + e)` space, where `e` is the number of edges, making it efficient for sparse graphs.\n",
    "- Iterating over all edges takes `O(n + e)` time.\n",
    "- Checking for the existence of an edge takes `O(d)` time, where `d` is the degree of the vertex.\n",
    "\n",
    "**Disadvantages**:\n",
    "- Slightly more complex to implement compared to the adjacency matrix.\n",
    "- Less efficient for dense graphs compared to the adjacency matrix.\n",
    "\n",
    "### Comparison\n",
    "\n",
    "| Feature                | Adjacency Matrix                  | Adjacency List                    |\n",
    "|------------------------|-----------------------------------|-----------------------------------|\n",
    "| Space Complexity       | `O(n^2)`                          | `O(n + e)`                        |\n",
    "| Edge Existence Check   | `O(1)`                            | `O(d)`                            |\n",
    "| Iterating Over Edges   | `O(n^2)`                          | `O(n + e)`                        |\n",
    "| Best for               | Dense graphs                      | Sparse graphs                     |\n",
    "| Implementation         | Simple                            | Slightly more complex             |\n",
    "\n",
    "### Summary\n",
    "\n",
    "Both adjacency matrix and adjacency list are common ways to represent graphs, each with its own advantages and disadvantages. The choice between them depends on the specific requirements of the application, such as the density of the graph and the operations that need to be performed efficiently. Adjacency matrices are better suited for dense graphs, while adjacency lists are more efficient for sparse graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: [1, 2]\n",
      "1: [0, 2]\n",
      "2: [0, 1, 3]\n",
      "3: [2]\n"
     ]
    }
   ],
   "source": [
    "class Graph:\n",
    "    def __init__(self):\n",
    "        # Initialize an empty dictionary to store the adjacency list\n",
    "        self.adjacency_list = {}\n",
    "\n",
    "    def add_vertex(self, vertex):\n",
    "        # Add a vertex to the graph\n",
    "        if vertex not in self.adjacency_list:\n",
    "            self.adjacency_list[vertex] = []\n",
    "\n",
    "    def add_edge(self, vertex1, vertex2):\n",
    "        # Add an edge between vertex1 and vertex2\n",
    "        if vertex1 in self.adjacency_list and vertex2 in self.adjacency_list:\n",
    "            self.adjacency_list[vertex1].append(vertex2)\n",
    "            self.adjacency_list[vertex2].append(vertex1)  # For undirected graph\n",
    "\n",
    "    def remove_edge(self, vertex1, vertex2):\n",
    "        # Remove an edge between vertex1 and vertex2\n",
    "        if vertex1 in self.adjacency_list and vertex2 in self.adjacency_list:\n",
    "            if vertex2 in self.adjacency_list[vertex1]:\n",
    "                self.adjacency_list[vertex1].remove(vertex2)\n",
    "            if vertex1 in self.adjacency_list[vertex2]:\n",
    "                self.adjacency_list[vertex2].remove(vertex1)\n",
    "\n",
    "    def remove_vertex(self, vertex):\n",
    "        # Remove a vertex and all its edges\n",
    "        if vertex in self.adjacency_list:\n",
    "            for adjacent in self.adjacency_list[vertex]:\n",
    "                self.adjacency_list[adjacent].remove(vertex)\n",
    "            del self.adjacency_list[vertex]\n",
    "\n",
    "    def display(self):\n",
    "        # Display the adjacency list\n",
    "        for vertex in self.adjacency_list:\n",
    "            print(f\"{vertex}: {self.adjacency_list[vertex]}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    graph = Graph()\n",
    "    graph.add_vertex(0)\n",
    "    graph.add_vertex(1)\n",
    "    graph.add_vertex(2)\n",
    "    graph.add_vertex(3)\n",
    "    graph.add_edge(0, 1)\n",
    "    graph.add_edge(0, 2)\n",
    "    graph.add_edge(1, 2)\n",
    "    graph.add_edge(2, 3)\n",
    "    graph.display()\n",
    "    # Output:\n",
    "    # 0: [1, 2]\n",
    "    # 1: [0, 2]\n",
    "    # 2: [0, 1, 3]\n",
    "    # 3: [2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breadth-First Search (BFS) and Depth-First Search (DFS)\n",
    "\n",
    "#### Breadth-First Search (BFS)\n",
    "\n",
    "**Definition**:\n",
    "Breadth-First Search (BFS) is an algorithm for traversing or searching tree or graph data structures. It starts at the root (or an arbitrary node) and explores the neighbor nodes at the present depth prior to moving on to nodes at the next depth level.\n",
    "\n",
    "**Algorithm**:\n",
    "1. Initialize a queue and enqueue the starting vertex.\n",
    "2. Mark the starting vertex as visited.\n",
    "3. While the queue is not empty:\n",
    "   - Dequeue a vertex from the queue.\n",
    "   - For each adjacent vertex, if it has not been visited, mark it as visited and enqueue it.\n",
    "\n",
    "\n",
    "#### Depth-First Search (DFS)\n",
    "\n",
    "**Definition**:\n",
    "Depth-First Search (DFS) is an algorithm for traversing or searching tree or graph data structures. It starts at the root (or an arbitrary node) and explores as far as possible along each branch before backtracking.\n",
    "\n",
    "**Algorithm**:\n",
    "1. Initialize a stack and push the starting vertex.\n",
    "2. Mark the starting vertex as visited.\n",
    "3. While the stack is not empty:\n",
    "   - Pop a vertex from the stack.\n",
    "   - For each adjacent vertex, if it has not been visited, mark it as visited and push it onto the stack.\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "### Comparison of BFS and DFS\n",
    "\n",
    "**Time Complexity**:\n",
    "- Both BFS and DFS have a time complexity of `O(V + E)`, where `V` is the number of vertices and `E` is the number of edges in the graph.\n",
    "\n",
    "**Space Complexity**:\n",
    "- BFS: `O(V)` for the queue and `O(V)` for the visited set, resulting in `O(V)` space complexity.\n",
    "- DFS: `O(V)` for the stack and `O(V)` for the visited set, resulting in `O(V)` space complexity.\n",
    "\n",
    "**Applications**:\n",
    "\n",
    "- **BFS**:\n",
    "  - Shortest Path: BFS is used to find the shortest path in an unweighted graph.\n",
    "  - Level Order Traversal: BFS is used for level order traversal of trees.\n",
    "  - Connectivity: BFS can be used to check if a graph is connected.\n",
    "\n",
    "- **DFS**:\n",
    "  - Path Finding: DFS is used to find a path between two vertices.\n",
    "  - Topological Sorting: DFS is used in topological sorting of a directed acyclic graph (DAG).\n",
    "  - Cycle Detection: DFS can be used to detect cycles in a graph.\n",
    "\n",
    "### Summary\n",
    "\n",
    "BFS and DFS are fundamental graph traversal algorithms with different strategies for exploring vertices. BFS explores vertices level by level, making it suitable for finding the shortest path in unweighted graphs. DFS explores as far as possible along each branch before backtracking, making it useful for pathfinding, topological sorting, and cycle detection. Both algorithms have the same time complexity but differ in their applications and traversal strategies.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFS traversal starting from vertex 0:\n",
      "0 1 2 3 "
     ]
    }
   ],
   "source": [
    "#Implementation of BFS\n",
    "from collections import deque\n",
    "\n",
    "def bfs(graph, start):\n",
    "    visited = set()\n",
    "    queue = deque([start])\n",
    "    visited.add(start)\n",
    "    \n",
    "    while queue:\n",
    "        vertex = queue.popleft()\n",
    "        print(vertex, end=\" \")\n",
    "        \n",
    "        for neighbor in graph[vertex]:\n",
    "            if neighbor not in visited:\n",
    "                visited.add(neighbor)\n",
    "                queue.append(neighbor)\n",
    "\n",
    "# Example usage\n",
    "graph = {\n",
    "    0: [1, 2],\n",
    "    1: [0, 2],\n",
    "    2: [0, 1, 3],\n",
    "    3: [2]\n",
    "}\n",
    "print(\"BFS traversal starting from vertex 0:\")\n",
    "bfs(graph, 0)\n",
    "# Output: 0 1 2 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DFS traversal starting from vertex 0:\n",
      "0 2 3 1 "
     ]
    }
   ],
   "source": [
    "#Implementation OF DFS:\n",
    "\n",
    "def dfs(graph, start):\n",
    "    visited = set()\n",
    "    stack = [start]\n",
    "    \n",
    "    while stack:\n",
    "        vertex = stack.pop()\n",
    "        if vertex not in visited:\n",
    "            print(vertex, end=\" \")\n",
    "            visited.add(vertex)\n",
    "            for neighbor in graph[vertex]:\n",
    "                if neighbor not in visited:\n",
    "                    stack.append(neighbor)\n",
    "\n",
    "# Example usage\n",
    "print(\"\\nDFS traversal starting from vertex 0:\")\n",
    "dfs(graph, 0)\n",
    "# Output: 0 2 3 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dijkstra’s Algorithm is a greedy algorithm used to find the shortest path between nodes in a graph, which may represent, for example, road networks. It works by iteratively selecting the vertex with the smallest tentative distance, expanding it, and updating the distances to its neighboring vertices until the shortest paths to all vertices are found.\n",
    "\n",
    "How Dijkstra’s Algorithm Works:\n",
    "\n",
    "Initialization:\n",
    "\n",
    "Assign a tentative distance value to every vertex. Set the distance to the source node to zero, and all other distances to infinity.\n",
    "Mark all nodes as unvisited. Set the initial node as the current node.\n",
    "\n",
    "Main Loop:\n",
    "\n",
    "For the current node, consider all of its unvisited neighbors and calculate their tentative distances through the current node.\n",
    "For each neighbor, if the calculated tentative distance is smaller than the current assigned value, update the shortest distance.\n",
    "After visiting all neighbors of the current node, mark it as visited. A visited node will not be checked again.\n",
    "\n",
    "Repeat:\n",
    "\n",
    "Select the unvisited node with the smallest tentative distance as the new current node, and repeat the process until all nodes have been visited.\n",
    "\n",
    "Termination:\n",
    "\n",
    "The algorithm finishes when all nodes have been visited or the smallest tentative distance among the unvisited nodes is infinity (indicating that no path exists)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shortest distance from A to A is 0\n",
      "The shortest distance from A to B is 1\n",
      "The shortest distance from A to C is 3\n",
      "The shortest distance from A to D is 4\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "\n",
    "# Dijkstra's algorithm implementation\n",
    "def dijkstra(graph, start):\n",
    "    # Dictionary to store the shortest path to each vertex\n",
    "    shortest_paths = {vertex: float('infinity') for vertex in graph}\n",
    "    shortest_paths[start] = 0  # Distance to the start node is 0\n",
    "    \n",
    "    # Priority queue to explore the nodes based on the shortest tentative distance\n",
    "    priority_queue = [(0, start)]  # (distance, vertex)\n",
    "    \n",
    "    while priority_queue:\n",
    "        current_distance, current_vertex = heapq.heappop(priority_queue)  # Get node with smallest tentative distance\n",
    "        \n",
    "        # If the distance is greater than the current shortest, continue\n",
    "        if current_distance > shortest_paths[current_vertex]:\n",
    "            continue\n",
    "        \n",
    "        # Explore neighbors\n",
    "        for neighbor, weight in graph[current_vertex].items():\n",
    "            distance = current_distance + weight\n",
    "            \n",
    "            # If a shorter path is found, update the shortest path\n",
    "            if distance < shortest_paths[neighbor]:\n",
    "                shortest_paths[neighbor] = distance\n",
    "                heapq.heappush(priority_queue, (distance, neighbor))  # Add to priority queue\n",
    "    \n",
    "    return shortest_paths\n",
    "\n",
    "# Example graph represented as an adjacency list\n",
    "graph = {\n",
    "    'A': {'B': 1, 'C': 4},\n",
    "    'B': {'A': 1, 'C': 2, 'D': 5},\n",
    "    'C': {'A': 4, 'B': 2, 'D': 1},\n",
    "    'D': {'B': 5, 'C': 1}\n",
    "}\n",
    "\n",
    "# Running the algorithm from the source node 'A'\n",
    "start_node = 'A'\n",
    "shortest_paths = dijkstra(graph, start_node)\n",
    "\n",
    "# Print the shortest paths from node 'A' to all other nodes\n",
    "for vertex, distance in shortest_paths.items():\n",
    "    print(f\"The shortest distance from {start_node} to {vertex} is {distance}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation of the Code:\n",
    "\n",
    "Graph Representation: The graph is represented as an adjacency list, where each node is a key, and its value is another dictionary representing neighboring nodes and their corresponding edge weights.\n",
    "\n",
    "Dijkstra Function:\n",
    "\n",
    "The function dijkstra() takes the graph and a start node as input.\n",
    "A dictionary shortest_paths is initialized with infinite distances (float('infinity')) for each vertex except the start node, which has a distance of 0.\n",
    "A priority queue (min-heap) is used to always explore the node with the smallest tentative distance.\n",
    "\n",
    "Main Loop:\n",
    "\n",
    "The algorithm extracts the node with the smallest distance from the priority queue and processes its neighbors.\n",
    "For each neighbor, it calculates the potential distance and updates it if a shorter path is found.\n",
    "This continues until all nodes have been visited.\n",
    "\n",
    "Priority Queue:\n",
    "\n",
    "The heap (heapq) ensures that the node with the smallest distance is efficiently retrieved and updated.\n",
    "Output: After running the algorithm, the shortest distance from the start node (A) to every other node is printed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimum Spanning Trees (MST) (5 Marks)\n",
    "\n",
    "#### Definition of Minimum Spanning Tree (MST)\n",
    "\n",
    "A Minimum Spanning Tree (MST) of a weighted, connected, undirected graph is a spanning tree with the minimum possible total edge weight. A spanning tree is a subgraph that includes all the vertices of the original graph and is a single connected tree.\n",
    "\n",
    "### Kruskal’s Algorithm\n",
    "\n",
    "**Explanation**:\n",
    "Kruskal's algorithm is a greedy algorithm that finds an MST by sorting all the edges in the graph by their weight and adding them one by one to the MST, ensuring no cycles are formed.\n",
    "\n",
    "**Steps**:\n",
    "1. Sort all the edges in non-decreasing order of their weight.\n",
    "2. Initialize an empty MST.\n",
    "3. Iterate through the sorted edges and add each edge to the MST if it does not form a cycle.\n",
    "4. Use a union-find data structure to detect cycles.\n",
    "\n",
    "**Implementation**:\n",
    "```python\n",
    "class DisjointSet:\n",
    "    def __init__(self, n):\n",
    "        self.parent = list(range(n))\n",
    "        self.rank = [0] * n\n",
    "\n",
    "    def find(self, u):\n",
    "        if self.parent[u] != u:\n",
    "            self.parent[u] = self.find(self.parent[u])\n",
    "        return self.parent[u]\n",
    "\n",
    "    def union(self, u, v):\n",
    "        root_u = self.find(u)\n",
    "        root_v = self.find(v)\n",
    "        if root_u != root_v:\n",
    "            if self.rank[root_u] > self.rank[root_v]:\n",
    "                self.parent[root_v] = root_u\n",
    "            elif self.rank[root_u] < self.rank[root_v]:\n",
    "                self.parent[root_u] = root_v\n",
    "            else:\n",
    "                self.parent[root_v] = root_u\n",
    "                self.rank[root_u] += 1\n",
    "\n",
    "def kruskal(graph, num_vertices):\n",
    "    edges = sorted(graph, key=lambda edge: edge[2])\n",
    "    disjoint_set = DisjointSet(num_vertices)\n",
    "    mst = []\n",
    "    for u, v, weight in edges:\n",
    "        if disjoint_set.find(u) != disjoint_set.find(v):\n",
    "            disjoint_set.union(u, v)\n",
    "            mst.append((u, v, weight))\n",
    "    return mst\n",
    "\n",
    "# Example usage\n",
    "graph = [\n",
    "    (0, 1, 10),\n",
    "    (0, 2, 6),\n",
    "    (0, 3, 5),\n",
    "    (1, 3, 15),\n",
    "    (2, 3, 4)\n",
    "]\n",
    "num_vertices = 4\n",
    "mst = kruskal(graph, num_vertices)\n",
    "print(\"Kruskal's MST:\", mst)\n",
    "# Output: Kruskal's MST: [(2, 3, 4), (0, 3, 5), (0, 1, 10)]\n",
    "```\n",
    "\n",
    "### Prim’s Algorithm\n",
    "\n",
    "**Explanation**:\n",
    "Prim's algorithm is a greedy algorithm that finds an MST by starting from an arbitrary vertex and growing the MST one edge at a time by adding the smallest edge that connects a vertex in the MST to a vertex outside the MST.\n",
    "\n",
    "**Steps**:\n",
    "1. Initialize an empty MST and a priority queue.\n",
    "2. Start from an arbitrary vertex and add all its edges to the priority queue.\n",
    "3. While the priority queue is not empty:\n",
    "   - Extract the edge with the minimum weight.\n",
    "   - If the edge connects a vertex in the MST to a vertex outside the MST, add it to the MST and add all edges of the new vertex to the priority queue.\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "### Comparison of Efficiencies\n",
    "\n",
    "**Time Complexity**:\n",
    "- **Kruskal's Algorithm**:\n",
    "  - Sorting edges: `O(E log E)`\n",
    "  - Union-Find operations: `O(E log V)` (using path compression and union by rank)\n",
    "  - Overall: `O(E log E)` or `O(E log V)` (since `E` can be at most `V^2`, `log E` is `O(log V)`)\n",
    "\n",
    "- **Prim's Algorithm**:\n",
    "  - Using a binary heap: `O(E log V)`\n",
    "  - Using a Fibonacci heap: `O(E + V log V)`\n",
    "\n",
    "**Space Complexity**:\n",
    "- Both algorithms require `O(V + E)` space to store the graph and additional data structures.\n",
    "\n",
    "**Applications**:\n",
    "- **Kruskal's Algorithm**:\n",
    "  - Suitable for sparse graphs (graphs with fewer edges).\n",
    "  - Easier to implement when the graph is represented as an edge list.\n",
    "\n",
    "- **Prim's Algorithm**:\n",
    "  - Suitable for dense graphs (graphs with more edges).\n",
    "  - More efficient with adjacency list representation and priority queue.\n",
    "\n",
    "### Summary\n",
    "\n",
    "Both Kruskal's and Prim's algorithms are efficient for finding the Minimum Spanning Tree (MST) of a graph. Kruskal's algorithm is better suited for sparse graphs and uses a union-find data structure to detect cycles. Prim's algorithm is more efficient for dense graphs and uses a priority queue to grow the MST. The choice between the two algorithms depends on the specific characteristics of the graph and the representation used.\n",
    "\n",
    "Similar code found with 2 license types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prim's MST: [(0, 1, 10), (0, 2, 6), (0, 3, 5), (3, 1, 15), (3, 2, 4)]\n"
     ]
    }
   ],
   "source": [
    "#Implementation\n",
    "import heapq\n",
    "\n",
    "def prim(graph, num_vertices):\n",
    "    mst = []\n",
    "    visited = [False] * num_vertices\n",
    "    min_heap = [(0, 0)]  # (weight, vertex)\n",
    "    total_weight = 0\n",
    "\n",
    "    while min_heap:\n",
    "        weight, u = heapq.heappop(min_heap)\n",
    "        if visited[u]:\n",
    "            continue\n",
    "        visited[u] = True\n",
    "        total_weight += weight\n",
    "        for v, w in graph[u]:\n",
    "            if not visited[v]:\n",
    "                heapq.heappush(min_heap, (w, v))\n",
    "                mst.append((u, v, w))\n",
    "\n",
    "    return mst\n",
    "\n",
    "# Example usage\n",
    "graph = {\n",
    "    0: [(1, 10), (2, 6), (3, 5)],\n",
    "    1: [(0, 10), (3, 15)],\n",
    "    2: [(0, 6), (3, 4)],\n",
    "    3: [(0, 5), (1, 15), (2, 4)]\n",
    "}\n",
    "num_vertices = 4\n",
    "mst = prim(graph, num_vertices)\n",
    "print(\"Prim's MST:\", mst)\n",
    "# Output: Prim's MST: [(0, 1, 10), (0, 2, 6), (0, 3, 5), (2, 3, 4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Foundational Tree Concepts \n",
    "\n",
    "#### Tree Terminology\n",
    "\n",
    "- **Tree**: A tree is a hierarchical data structure consisting of nodes, with a single node called the root, and zero or more subtrees.\n",
    "- **Root**: The topmost node of a tree. It has no parent.\n",
    "- **Parent**: A node that has one or more child nodes.\n",
    "- **Child**: A node that is a descendant of another node (its parent).\n",
    "- **Leaf**: A node that has no children.\n",
    "- **Sibling**: Nodes that share the same parent.\n",
    "- **Ancestor**: A node that is connected to another node by a path of edges going upwards.\n",
    "- **Descendant**: A node that is connected to another node by a path of edges going downwards.\n",
    "- **Subtree**: A tree consisting of a node and all its descendants.\n",
    "- **Height**: The length of the longest path from the root to a leaf.\n",
    "- **Depth**: The length of the path from the root to a given node.\n",
    "\n",
    "#### Tree Representations\n",
    "\n",
    "1. **Linked Lists**:\n",
    "   - Each node contains data and references (pointers) to its children.\n",
    "   - Commonly used for binary trees where each node has at most two children (left and right).\n",
    "\n",
    "   ```python\n",
    "   class TreeNode:\n",
    "       def __init__(self, value):\n",
    "           self.value = value\n",
    "           self.left = None\n",
    "           self.right = None\n",
    "   ```\n",
    "\n",
    "2. **Arrays**:\n",
    "   - Trees can be represented using arrays, especially binary heaps.\n",
    "   - For a binary tree, the root is at index 0. For a node at index `i`, its left child is at `2*i + 1` and its right child is at `2*i + 2`.\n",
    "\n",
    "   ```python\n",
    "   tree = [None] * 10  # Example array representation of a tree\n",
    "   tree[0] = 'A'  # Root\n",
    "   tree[1] = 'B'  # Left child of root\n",
    "   tree[2] = 'C'  # Right child of root\n",
    "   ```\n",
    "\n",
    "#### Tree Traversal Techniques\n",
    "\n",
    "1. **Inorder Traversal** (Left, Root, Right):\n",
    "   - Visit the left subtree, the root node, and then the right subtree.\n",
    "   - Used for binary search trees to retrieve elements in sorted order.\n",
    "\n",
    "   ```python\n",
    "   def inorder_traversal(root):\n",
    "       if root:\n",
    "           inorder_traversal(root.left)\n",
    "           print(root.value, end=' ')\n",
    "           inorder_traversal(root.right)\n",
    "\n",
    "   # Example usage\n",
    "   root = TreeNode('A')\n",
    "   root.left = TreeNode('B')\n",
    "   root.right = TreeNode('C')\n",
    "   root.left.left = TreeNode('D')\n",
    "   root.left.right = TreeNode('E')\n",
    "   print(\"Inorder Traversal:\")\n",
    "   inorder_traversal(root)  # Output: D B E A C\n",
    "   ```\n",
    "\n",
    "2. **Preorder Traversal** (Root, Left, Right):\n",
    "   - Visit the root node, the left subtree, and then the right subtree.\n",
    "   - Used to create a copy of the tree.\n",
    "\n",
    "   ```python\n",
    "   def preorder_traversal(root):\n",
    "       if root:\n",
    "           print(root.value, end=' ')\n",
    "           preorder_traversal(root.left)\n",
    "           preorder_traversal(root.right)\n",
    "\n",
    "   # Example usage\n",
    "   print(\"\\nPreorder Traversal:\")\n",
    "   preorder_traversal(root)  # Output: A B D E C\n",
    "   ```\n",
    "\n",
    "3. **Postorder Traversal** (Left, Right, Root):\n",
    "   - Visit the left subtree, the right subtree, and then the root node.\n",
    "   - Used to delete the tree.\n",
    "\n",
    "   ```python\n",
    "   def postorder_traversal(root):\n",
    "       if root:\n",
    "           postorder_traversal(root.left)\n",
    "           postorder_traversal(root.right)\n",
    "           print(root.value, end=' ')\n",
    "\n",
    "   # Example usage\n",
    "   print(\"\\nPostorder Traversal:\")\n",
    "   postorder_traversal(root)  # Output: D E B C A\n",
    "   ```\n",
    "\n",
    "4. **Breadth-First Search (BFS) / Level Order Traversal**:\n",
    "   - Visit nodes level by level from left to right.\n",
    "   - Uses a queue to keep track of nodes at the current level.\n",
    "\n",
    "   ```python\n",
    "   from collections import deque\n",
    "\n",
    "   def bfs_traversal(root):\n",
    "       if not root:\n",
    "           return\n",
    "       queue = deque([root])\n",
    "       while queue:\n",
    "           node = queue.popleft()\n",
    "           print(node.value, end=' ')\n",
    "           if node.left:\n",
    "               queue.append(node.left)\n",
    "           if node.right:\n",
    "               queue.append(node.right)\n",
    "\n",
    "   # Example usage\n",
    "   print(\"\\nBFS Traversal:\")\n",
    "   bfs_traversal(root)  # Output: A B C D E\n",
    "   ```\n",
    "\n",
    "### Summary\n",
    "\n",
    "Trees are hierarchical data structures with various terminologies such as root, parent, child, leaf, and more. They can be represented using linked lists or arrays. Tree traversal techniques include inorder, preorder, postorder, and BFS, each serving different purposes and applications. Understanding these concepts and implementations is fundamental for working with tree data structures in computer science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary Search Tree (BST):\n",
    "A Binary Search Tree (BST) is a type of binary tree in which each node follows these properties:\n",
    "\n",
    "Left Subtree: The value of every node in the left subtree is less than the value of the parent node.\n",
    "\n",
    "Right Subtree: The value of every node in the right subtree is greater than the value of the parent node.\n",
    "\n",
    "No Duplicates: In a typical BST, there are no duplicate nodes; each value appears only once.\n",
    "Binary Tree Structure: Each node has at most two children (left and right).\n",
    "\n",
    "Properties of BST:\n",
    "Search Operation: The BST property allows for efficient searching of elements. The search time complexity is O(h), where h is the height of the tree. For a balanced tree, this is O(log n), where n is the number of nodes in the tree.\n",
    "\n",
    "Insertion: When inserting a new node, the tree remains a BST by placing the new node in the correct position based on its value, which results in a time complexity of O(h).\n",
    "\n",
    "Deletion: Deleting a node requires searching for the node, and depending on the number of children the node has, the deletion operation can be a bit more involved. Deletion also runs in O(h) time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inorder traversal of the BST:\n",
      "20 30 40 50 60 70 80 \n",
      "\n",
      "Node with value 40 found.\n",
      "Node with value 25 not found.\n",
      "\n",
      "Inorder traversal after deleting 20:\n",
      "30 40 50 60 70 80 \n",
      "\n",
      "\n",
      "Inorder traversal after deleting 30:\n",
      "40 50 60 70 80 \n",
      "\n",
      "\n",
      "Inorder traversal after deleting 50:\n",
      "40 60 70 80 "
     ]
    }
   ],
   "source": [
    "class Node:\n",
    "    def __init__(self, key):\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.value = key\n",
    "\n",
    "class BST:\n",
    "    def __init__(self):\n",
    "        self.root = None\n",
    "\n",
    "    # Insertion Method\n",
    "    def insert(self, root, key):\n",
    "        # If the tree is empty, return a new node\n",
    "        if root is None:\n",
    "            return Node(key)\n",
    "        \n",
    "        # Otherwise, recur down the tree\n",
    "        if key < root.value:\n",
    "            root.left = self.insert(root.left, key)\n",
    "        elif key > root.value:\n",
    "            root.right = self.insert(root.right, key)\n",
    "        \n",
    "        # Return the (unchanged) node pointer\n",
    "        return root\n",
    "\n",
    "    # Helper method to call the insert method\n",
    "    def insert_value(self, key):\n",
    "        self.root = self.insert(self.root, key)\n",
    "\n",
    "    # Search Method\n",
    "    def search(self, root, key):\n",
    "        # Base cases: root is null or key is present at the root\n",
    "        if root is None or root.value == key:\n",
    "            return root\n",
    "        \n",
    "        # Key is greater than root's key\n",
    "        if key > root.value:\n",
    "            return self.search(root.right, key)\n",
    "        \n",
    "        # Key is smaller than root's key\n",
    "        return self.search(root.left, key)\n",
    "\n",
    "    # Helper method to call the search method\n",
    "    def search_value(self, key):\n",
    "        result = self.search(self.root, key)\n",
    "        if result:\n",
    "            return f\"Node with value {key} found.\"\n",
    "        else:\n",
    "            return f\"Node with value {key} not found.\"\n",
    "    \n",
    "    # Deletion Method\n",
    "    def delete(self, root, key):\n",
    "        # Base case: If the tree is empty\n",
    "        if root is None:\n",
    "            return root\n",
    "        \n",
    "        # Otherwise, recur down the tree\n",
    "        if key < root.value:\n",
    "            root.left = self.delete(root.left, key)\n",
    "        elif key > root.value:\n",
    "            root.right = self.delete(root.right, key)\n",
    "        \n",
    "        # If key is the same as root's value, then this is the node to be deleted\n",
    "        else:\n",
    "            # Node with only one child or no child\n",
    "            if root.left is None:\n",
    "                temp = root.right\n",
    "                root = None\n",
    "                return temp\n",
    "            elif root.right is None:\n",
    "                temp = root.left\n",
    "                root = None\n",
    "                return temp\n",
    "            \n",
    "            # Node with two children: Get the inorder successor (smallest in the right subtree)\n",
    "            temp = self.min_value_node(root.right)\n",
    "            \n",
    "            # Copy the inorder successor's content to this node\n",
    "            root.value = temp.value\n",
    "            \n",
    "            # Delete the inorder successor\n",
    "            root.right = self.delete(root.right, temp.value)\n",
    "        \n",
    "        return root\n",
    "    \n",
    "    # Helper method to call the delete method\n",
    "    def delete_value(self, key):\n",
    "        self.root = self.delete(self.root, key)\n",
    "\n",
    "    # Utility function to find the node with the minimum value\n",
    "    def min_value_node(self, node):\n",
    "        current = node\n",
    "        # Loop down to find the leftmost leaf\n",
    "        while current.left is not None:\n",
    "            current = current.left\n",
    "        return current\n",
    "\n",
    "    # Inorder traversal (for testing purposes)\n",
    "    def inorder(self, root):\n",
    "        if root:\n",
    "            self.inorder(root.left)\n",
    "            print(root.value, end=\" \")\n",
    "            self.inorder(root.right)\n",
    "\n",
    "    # Helper method to call the inorder traversal\n",
    "    def inorder_traversal(self):\n",
    "        self.inorder(self.root)\n",
    "\n",
    "# Driver code to test the BST operations\n",
    "bst = BST()\n",
    "\n",
    "# Insert values\n",
    "bst.insert_value(50)\n",
    "bst.insert_value(30)\n",
    "bst.insert_value(20)\n",
    "bst.insert_value(40)\n",
    "bst.insert_value(70)\n",
    "bst.insert_value(60)\n",
    "bst.insert_value(80)\n",
    "\n",
    "# Print inorder traversal (should print sorted elements)\n",
    "print(\"Inorder traversal of the BST:\")\n",
    "bst.inorder_traversal()  # Expected output: 20 30 40 50 60 70 80\n",
    "print(\"\\n\")\n",
    "\n",
    "# Search operation\n",
    "print(bst.search_value(40))  # Expected output: \"Node with value 40 found.\"\n",
    "print(bst.search_value(25))  # Expected output: \"Node with value 25 not found.\"\n",
    "\n",
    "# Deletion operation\n",
    "bst.delete_value(20)\n",
    "print(\"\\nInorder traversal after deleting 20:\")\n",
    "bst.inorder_traversal()  # Expected output: 30 40 50 60 70 80\n",
    "print(\"\\n\")\n",
    "\n",
    "bst.delete_value(30)\n",
    "print(\"\\nInorder traversal after deleting 30:\")\n",
    "bst.inorder_traversal()  # Expected output: 40 50 60 70 80\n",
    "print(\"\\n\")\n",
    "\n",
    "bst.delete_value(50)\n",
    "print(\"\\nInorder traversal after deleting 50:\")\n",
    "bst.inorder_traversal()  # Expected output: 40 60 70 80\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation of the Code:\n",
    "Node Class:\n",
    "\n",
    "Each Node object represents a node in the tree with three attributes:\n",
    "left: Left child of the node.\n",
    "right: Right child of the node.\n",
    "value: The data stored in the node.\n",
    "BST Class:\n",
    "\n",
    "The BST class represents the binary search tree.\n",
    "Insert: The insert() method adds a new value to the tree following the BST property. The insertion is done recursively until we find the correct position for the new node.\n",
    "\n",
    "Search: The search() method recursively looks for a value in the tree. If the value is smaller than the current node, the search continues in the left subtree. If the value is larger, it continues in the right subtree.\n",
    "\n",
    "Delete: The delete() method removes a node from the tree. It handles three cases:\n",
    "Node with no children (leaf node).\n",
    "Node with one child.\n",
    "\n",
    "Node with two children (find the inorder successor, replace the node, and delete the successor).\n",
    "\n",
    "Inorder Traversal: This is a helper function to print the elements of the BST in sorted order.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time Complexity:\n",
    "\n",
    "Insertion, Deletion, Search: Each of these operations takes O(h) time, where h is the height of the tree.\n",
    "\n",
    "In the best case (balanced tree), the height is O(log n), where n is the number of nodes.\n",
    "In the worst case (skewed tree), the height is O(n).\n",
    "\n",
    "Space Complexity:\n",
    "O(n) for storing n nodes in the tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search Time Complexity:\n",
    "\n",
    "Binary Search Tree (BST):\n",
    "\n",
    "Time Complexity:\n",
    "\n",
    "In the best case, a balanced BST has a time complexity of O(log n) for searching, where n is the number of nodes in the tree. This is because, at each level, the search space is halved (similar to binary search).\n",
    "\n",
    "In the worst case, if the BST is unbalanced (i.e., if the tree is a straight line), the time complexity could degrade to O(n) because you would have to traverse the entire tree (like a linked list).\n",
    "\n",
    "Example:\n",
    "Balanced BST: Searching for a node with value X takes at most log n steps.\n",
    "Unbalanced BST: Searching for a node could take n steps in the worst case.\n",
    "\n",
    "\n",
    "Unsorted Array:\n",
    "Time Complexity:\n",
    "Searching in an unsorted array requires linear search in the worst case. This means that in the worst case, we might need to check every element in the array, resulting in O(n) time complexity.\n",
    "\n",
    "Example:\n",
    "If you want to find a node with value X, you might have to look through all the elements of the array until you find it (or determine that it doesn't exist)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time Complexity of Operations on Trees\n",
    "\n",
    "A tree is a hierarchical data structure where each node has a value and references to its child nodes. The time complexity of operations on trees depends on the structure of the tree (whether it's balanced or unbalanced) and the type of tree being used. Below is a detailed analysis of the time complexities for basic tree operations.\n",
    "\n",
    "1. Insertion\n",
    "Balanced Tree (e.g., AVL, Red-Black Tree):\n",
    "Time Complexity: O(log n)\n",
    "In a balanced tree, the height of the tree is kept to a minimum (i.e., log n), so inserting an element takes O(log n) time as we need to traverse down the tree and possibly adjust the structure to maintain balance.\n",
    "Unbalanced Tree (e.g., simple Binary Tree, if unbalanced):\n",
    "\n",
    "Time Complexity: O(n)\n",
    "In the worst case, for an unbalanced tree (such as a degenerate tree), the tree can become a linked list with height n. Therefore, inserting a new node may require traversing all nodes, resulting in O(n) time.\n",
    "\n",
    "2. Deletion\n",
    "Balanced Tree (e.g., AVL, Red-Black Tree):\n",
    "Time Complexity: O(log n)\n",
    "Deleting a node from a balanced tree requires searching for the node, which takes O(log n) time, followed by possibly rebalancing the tree, which also takes O(log n).\n",
    "\n",
    "Unbalanced Tree:\n",
    "\n",
    "Time Complexity: O(n)\n",
    "If the tree is unbalanced, deleting a node might require traversing a path that could be as long as the height of the tree, which could be O(n) in the worst case.\n",
    "\n",
    "3. Searching\n",
    "Balanced Tree:\n",
    "\n",
    "Time Complexity: O(log n)\n",
    "Searching for a node in a balanced tree is efficient, as the height of the tree is minimized, leading to a logarithmic search time.\n",
    "\n",
    "Unbalanced Tree:\n",
    "\n",
    "Time Complexity: O(n)\n",
    "In an unbalanced tree, searching for a node may require traversing a long path, resulting in linear time complexity.\n",
    "\n",
    "4. Traversal\n",
    "Tree traversals can be done in several ways: Inorder, Preorder, Postorder, and Level-order. All of these are relatively straightforward and visit each node once, so their time complexities are:\n",
    "\n",
    "Time Complexity: O(n)\n",
    "Traversing a tree involves visiting all nodes, so the time complexity is linear in the number of nodes for all standard tree traversal algorithms.\n",
    "\n",
    "5. Balancing (for Self-balancing Trees like AVL, Red-Black Tree)\n",
    "\n",
    "Time Complexity: O(log n)\n",
    "\n",
    "Balancing a tree requires checking the balance condition and rotating nodes to maintain a balanced structure. This can be done in logarithmic time, making it efficient for trees that need to maintain a balance after every insertion or deletion.\n",
    "\n",
    "Importance of Balanced Trees\n",
    "Balanced trees are crucial because they ensure that the height of the tree remains small, which directly impacts the time complexity of operations. When trees are balanced, operations such as searching, insertion, and deletion can be performed in O(log n) time, which is significantly faster than in an unbalanced tree.\n",
    "\n",
    "Why Balance is Important:\n",
    "\n",
    "Efficiency in Operations:\n",
    "\n",
    "In a balanced tree, the maximum height is kept small (around log n), leading to faster access times for operations like search, insertion, and deletion. This is especially important in data structures like binary search trees (BST), where searching for an element is dependent on the height of the tree.\n",
    "\n",
    "Minimized Depth:\n",
    "\n",
    "A balanced tree minimizes the depth of the tree, which is the number of edges from the root to the deepest leaf. The shallower the tree, the faster it is to traverse.\n",
    "\n",
    "Avoiding Degeneration:\n",
    "\n",
    "In an unbalanced tree, if the tree degenerates into a linked list (like in the case of sequential insertions), all operations could degrade to O(n). For example, searching for a node would involve traversing all nodes in a straight line, which is inefficient.\n",
    "\n",
    "Self-balancing Trees:\n",
    "\n",
    "Some tree structures like AVL trees and Red-Black trees automatically balance themselves upon insertion and deletion to ensure that the height remains logarithmic. This ensures that all operations remain efficient.\n",
    "\n",
    "Real-World Applications of Trees\n",
    "\n",
    "Trees are used in various applications in computer science and real-world systems because they provide an efficient way to store and manage hierarchical data. Here are two examples of real-world applications:\n",
    "\n",
    "1. File Systems:\n",
    "\n",
    "Most operating systems, such as Windows, Linux, and macOS, use tree structures to represent their file systems. The root of the tree represents the root directory, and each node represents a file or subdirectory.\n",
    "In such file systems, tree operations like searching for files, inserting new files, and deleting files are required frequently. A balanced tree structure ensures that these operations are done efficiently.\n",
    "Example: NTFS (New Technology File System) in Windows is a tree-based system that organizes files and directories in a hierarchical manner, using B-trees for indexing.\n",
    "\n",
    "2. Database Indexing:\n",
    "\n",
    "Databases like MySQL, PostgreSQL, and MongoDB use tree structures (often B-trees and B+ trees) for indexing. These trees are used to speed up search, insertion, and deletion operations in large databases.\n",
    "For instance, when you query a database to retrieve data, the system uses a tree structure to quickly locate the data without scanning all records.\n",
    "The use of balanced trees like B-trees ensures that database operations remain efficient, even with a large amount of data.\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "Time Complexity Analysis:\n",
    "\n",
    "Operations like insertion, deletion, and search in trees depend heavily on the tree's balance. For balanced trees, these operations can be done in O(log n) time, whereas for unbalanced trees, they can degrade to O(n).\n",
    "\n",
    "Importance of Balanced Trees:\n",
    "\n",
    "Balanced trees ensure that tree operations are efficient, preventing performance degradation and ensuring that the height remains logarithmic. Self-balancing trees like AVL trees and Red-Black trees help maintain this balance automatically.\n",
    "\n",
    "Real-World Applications:\n",
    "\n",
    "Trees are used extensively in applications like file systems and database indexing due to their efficiency in organizing and searching hierarchical data. Their ability to provide quick access to data makes them indispensable in modern computing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
